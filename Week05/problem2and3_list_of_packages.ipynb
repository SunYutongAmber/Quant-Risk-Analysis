{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem2\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import norm, t\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "data = pd.read_csv(\"problem1.csv\")\n",
    "portfolio = pd.read_csv(\"portfolio.csv\")\n",
    "prices = pd.read_csv(\"DailyPrices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Estimation\n",
    "def multivariate_normal_simulation(covariance_matrix, n_samples, method='direct', mean = 0, explained_variance=1.0):\n",
    "    if method == 'direct':      \n",
    "        L = psd(covariance_matrix)\n",
    "        normal_samples = np.random.normal(size=(covariance_matrix.shape[0], n_samples))       \n",
    "        samples = np.transpose(np.dot(L, normal_samples) + mean)        \n",
    "        return samples \n",
    "    elif method == 'pca':\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "        idx = eigenvalues > 1e-8\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        if explained_variance == 1.0:\n",
    "            explained_variance = (np.cumsum(eigenvalues)/np.sum(eigenvalues))[-1]\n",
    "        n_components = np.where((np.cumsum(eigenvalues)/np.sum(eigenvalues))>= explained_variance)[0][0] + 1\n",
    "        eigenvectors = eigenvectors[:,:n_components]\n",
    "        eigenvalues = eigenvalues[:n_components]\n",
    "        normal_samples = np.random.normal(size=(n_components, n_samples))\n",
    "        B = np.dot(eigenvectors, np.diag(np.sqrt(eigenvalues)))\n",
    "        samples = np.transpose(np.dot(B, normal_samples))      \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-PSD fixes for correlation matrix\n",
    "def psd(a):\n",
    "    n= a.shape[0]\n",
    "    root = np.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        s=0\n",
    "        if j>0:\n",
    "            s = root[j,:j].T @ root[j,:j]\n",
    "        temp = a[j,j] - s\n",
    "        if temp <= 0 and temp >= -1e-8:\n",
    "            temp =0\n",
    "        root[j,j] = math.sqrt(temp)\n",
    "        if root[j,j] == 0:\n",
    "            root[j+1:n,j] = 0\n",
    "        else:\n",
    "            ir = 1/root[j,j]\n",
    "            for i in range(j+1,n):\n",
    "                s = root[i,:j].T @ root[j,:j]\n",
    "                root[i,j] = (a[i,j]-s)*ir\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Expected Shortfalls\n",
    "def ES(a,alpha=0.05):\n",
    "    a.sort()\n",
    "    v= np.quantile(a,alpha)\n",
    "    es = a[a<=v].mean()\n",
    "    return -es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Value at Risk\n",
    "def VaR(a,alpha=0.05):\n",
    "    a.sort()\n",
    "    v= np.quantile(a,alpha)\n",
    "    return -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MLE_T(params, returns):\n",
    "    negLL = -1 * np.sum(stats.t.logpdf(returns, df=params[0], loc=params[1], scale=params[2]))\n",
    "    return(negLL)\n",
    "def Fitting_t_MLE(returns):\n",
    "    constraints=({\"type\":\"ineq\", \"fun\":lambda x: x[0]-1}, {\"type\":\"ineq\", \"fun\":lambda x: x[2]})\n",
    "    returns_t = minimize(MLE_T, x0=[10, np.mean(returns), np.std(returns)], args=returns, constraints=constraints)\n",
    "    df, loc, scale = returns_t.x[0], returns_t.x[1], returns_t.x[2]\n",
    "    return df, loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at Risk (VaR): 4.108218379832072\n",
      "Expected Shortfall (ES): 4.781323266046413\n",
      "MLE parameters for t-distribution (df, loc, scale): 294.4151369120474 -1.3955999112137918 1.7116827468031655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/lm0km0mn4zlf79tvv2679h740000gn/T/ipykernel_26178/1593357208.py:14: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  returns = np.random.multivariate_normal(mean_returns, covariance_matrix, num_samples).T\n"
     ]
    }
   ],
   "source": [
    "#generate a suitcase to test the code\n",
    "\n",
    "# Function to generate a random dataset\n",
    "def generate_random_data(num_samples, num_assets):\n",
    "    # Generate random covariance matrix\n",
    "    covariance_matrix = np.random.randn(num_assets, num_assets)\n",
    "    covariance_matrix = np.dot(covariance_matrix, covariance_matrix.T)\n",
    "    np.fill_diagonal(covariance_matrix, 1.0)  # Make diagonal elements 1\n",
    "\n",
    "    # Generate random mean returns\n",
    "    mean_returns = np.random.randn(num_assets)\n",
    "\n",
    "    # Generate random returns using a multivariate normal distribution\n",
    "    returns = np.random.multivariate_normal(mean_returns, covariance_matrix, num_samples).T\n",
    "\n",
    "    return returns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate random data with 1000 samples and 5 assets\n",
    "num_samples = 1000\n",
    "num_assets = 5\n",
    "returns_data = generate_random_data(num_samples, num_assets)\n",
    "\n",
    "# Calculate Value at Risk (VaR) and Expected Shortfall (ES)\n",
    "alpha = 0.05\n",
    "var_value = VaR(returns_data[0], alpha)\n",
    "es_value = ES(returns_data[0], alpha)\n",
    "\n",
    "print(\"Value at Risk (VaR):\", var_value)\n",
    "print(\"Expected Shortfall (ES):\", es_value)\n",
    "\n",
    "# Perform Maximum Likelihood Estimation for t-distribution parameters\n",
    "df, loc, scale = Fitting_t_MLE(returns_data[0])\n",
    "print(\"MLE parameters for t-distribution (df, loc, scale):\", df, loc, scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 3\n",
    "def return_calculate(prices, method=\"DISCRETE\", dateColumn=\"Date\"):\n",
    "    vars_ = prices.columns\n",
    "    nVars = len(vars_)\n",
    "    vars_ = [var for var in vars_ if var != dateColumn]\n",
    "    if nVars == len(vars_):\n",
    "        raise ValueError(f\"dateColumn: {dateColumn} not in DataFrame: {vars_}\")\n",
    "    nVars = nVars - 1\n",
    "    p = prices[vars_].to_numpy()\n",
    "    n, m = p.shape\n",
    "    p2 = np.empty((n-1, m))\n",
    "    if method.upper() == \"DISCRETE\" or method.upper() == \"LOG\":\n",
    "    # Calculate returns\n",
    "        for i in range(n - 1):\n",
    "            for j in range(m):\n",
    "                p2[i, j] = p[i + 1, j] / p[i, j]\n",
    "        \n",
    "        if method.upper() == \"DISCRETE\":\n",
    "            p2 = p2 - 1.0\n",
    "        else:\n",
    "            p2 = np.log(p2)\n",
    "    elif method.upper() == \"CLASSIC\":\n",
    "        for i in range(n - 1):\n",
    "            for j in range(m):\n",
    "                p2[i, j] = p[i + 1, j] - p[i, j]\n",
    "    else:\n",
    "        raise ValueError(f\"method: {method} must be in ('LOG', 'DISCRETE', 'CLASSIC')\")\n",
    "    dates = prices[dateColumn].iloc[1:n].to_numpy()\n",
    "    out = pd.DataFrame({dateColumn: dates})\n",
    "    for i in range(nVars):\n",
    "        out[vars_[i]] = p2[:, i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio_price(portfolio, prices, portfolio_code, Delta=False):\n",
    "    if portfolio_code == \"All\":\n",
    "        assets = portfolio.drop('Portfolio',axis=1)\n",
    "        assets = assets.groupby([\"Stock\"], as_index=False)[\"Holding\"].sum()\n",
    "    else:\n",
    "        assets = portfolio[portfolio[\"Portfolio\"] == portfolio_code]        \n",
    "    stock_codes = list(assets[\"Stock\"])\n",
    "    assets_prices = pd.concat([prices[\"Date\"], prices[stock_codes]], axis=1)  \n",
    "    current_price = np.dot(prices[assets[\"Stock\"]].tail(1), assets[\"Holding\"])\n",
    "    holdings = assets[\"Holding\"]    \n",
    "    if Delta == True:\n",
    "        asset_values = assets[\"Holding\"].values.reshape(-1, 1) * prices[assets[\"Stock\"]].tail(1).T.values\n",
    "        delta = asset_values / current_price    \n",
    "        return current_price, assets_prices, delta   \n",
    "    return current_price, assets_prices, holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR： 21060.107433205387\n",
      "ES： 28279.714487442863\n"
     ]
    }
   ],
   "source": [
    "asset = 'A'\n",
    "current_price, assets_prices, holdings = get_portfolio_price(portfolio, prices, asset)\n",
    "assets_returns = return_calculate(assets_prices)\n",
    "assets_returns.drop('Date', axis=1, inplace=True)\n",
    "norm_assets_returns = assets_returns - assets_returns.mean()\n",
    "parameters = []\n",
    "assets_returns_cdf = pd.DataFrame()\n",
    "\n",
    "for stock in norm_assets_returns.columns.tolist():\n",
    "    params = Fitting_t_MLE(norm_assets_returns[stock])\n",
    "    parameters.append(params)\n",
    "    assets_returns_cdf[stock] = stats.t.cdf(norm_assets_returns[stock], df=params[0], loc=params[1], scale=params[2])\n",
    "spearman_corr_matrix = assets_returns_cdf.corr(method='spearman')\n",
    "sim_sample = multivariate_normal_simulation(spearman_corr_matrix, 1000, method='pca')\n",
    "sim_sample = pd.DataFrame(sim_sample, columns=assets_returns.columns)\n",
    "sim_sample_cdf = pd.DataFrame()\n",
    "for stock in sim_sample.columns.tolist():\n",
    "    sim_sample_cdf[stock] = stats.norm.cdf(sim_sample[stock], loc=0, scale=1)\n",
    "\n",
    "sim_returns = pd.DataFrame()\n",
    "for i, stock in enumerate(sim_sample.columns.tolist()):\n",
    "    sim_returns[stock] = stats.t.ppf(sim_sample_cdf[stock], df=parameters[i][0], loc=parameters[i][1], scale=parameters[i][2])\n",
    "\n",
    "assets_prices.drop('Date', axis=1, inplace=True)\n",
    "sim_prices = np.dot(sim_returns * assets_prices.tail(1).values.reshape(assets_prices.shape[1],), holdings)\n",
    "\n",
    "var_T = VaR(sim_prices)\n",
    "es_T = ES(sim_prices)\n",
    "\n",
    "print(\"VaR： {}\".format(var_T))\n",
    "print(\"ES： {}\".format(es_T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR： 12042.618933706053\n",
      "ES： 16132.638858042772\n"
     ]
    }
   ],
   "source": [
    "asset = 'B'\n",
    "current_price, assets_prices, holdings = get_portfolio_price(portfolio, prices, asset)\n",
    "assets_returns = return_calculate(assets_prices)\n",
    "assets_returns.drop('Date', axis=1, inplace=True)\n",
    "norm_assets_returns = assets_returns - assets_returns.mean()\n",
    "parameters = []\n",
    "assets_returns_cdf = pd.DataFrame()\n",
    "\n",
    "for stock in norm_assets_returns.columns.tolist():\n",
    "    params = Fitting_t_MLE(norm_assets_returns[stock])\n",
    "    parameters.append(params)\n",
    "    assets_returns_cdf[stock] = stats.t.cdf(norm_assets_returns[stock], df=params[0], loc=params[1], scale=params[2])\n",
    "spearman_corr_matrix = assets_returns_cdf.corr(method='spearman')\n",
    "sim_sample = multivariate_normal_simulation(spearman_corr_matrix, 1000, method='pca')\n",
    "sim_sample = pd.DataFrame(sim_sample, columns=assets_returns.columns)\n",
    "sim_sample_cdf = pd.DataFrame()\n",
    "for stock in sim_sample.columns.tolist():\n",
    "    sim_sample_cdf[stock] = stats.norm.cdf(sim_sample[stock], loc=0, scale=1)\n",
    "\n",
    "sim_returns = pd.DataFrame()\n",
    "for i, stock in enumerate(sim_sample.columns.tolist()):\n",
    "    sim_returns[stock] = stats.t.ppf(sim_sample_cdf[stock], df=parameters[i][0], loc=parameters[i][1], scale=parameters[i][2])\n",
    "\n",
    "assets_prices.drop('Date', axis=1, inplace=True)\n",
    "sim_prices = np.dot(sim_returns * assets_prices.tail(1).values.reshape(assets_prices.shape[1],), holdings)\n",
    "\n",
    "var_T = VaR(sim_prices)\n",
    "es_T = ES(sim_prices)\n",
    "\n",
    "print(\"VaR： {}\".format(var_T))\n",
    "print(\"ES： {}\".format(es_T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR： 26476.66385351571\n",
      "ES： 35311.08349690529\n"
     ]
    }
   ],
   "source": [
    "asset = 'C'\n",
    "current_price, assets_prices, holdings = get_portfolio_price(portfolio, prices, asset)\n",
    "assets_returns = return_calculate(assets_prices)\n",
    "assets_returns.drop('Date', axis=1, inplace=True)\n",
    "norm_assets_returns = assets_returns - assets_returns.mean()\n",
    "parameters = []\n",
    "assets_returns_cdf = pd.DataFrame()\n",
    "\n",
    "for stock in norm_assets_returns.columns.tolist():\n",
    "    params = Fitting_t_MLE(norm_assets_returns[stock])\n",
    "    parameters.append(params)\n",
    "    assets_returns_cdf[stock] = stats.t.cdf(norm_assets_returns[stock], df=params[0], loc=params[1], scale=params[2])\n",
    "spearman_corr_matrix = assets_returns_cdf.corr(method='spearman')\n",
    "sim_sample = multivariate_normal_simulation(spearman_corr_matrix, 1000, method='pca')\n",
    "sim_sample = pd.DataFrame(sim_sample, columns=assets_returns.columns)\n",
    "sim_sample_cdf = pd.DataFrame()\n",
    "for stock in sim_sample.columns.tolist():\n",
    "    sim_sample_cdf[stock] = stats.norm.cdf(sim_sample[stock], loc=0, scale=1)\n",
    "\n",
    "sim_returns = pd.DataFrame()\n",
    "for i, stock in enumerate(sim_sample.columns.tolist()):\n",
    "    sim_returns[stock] = stats.t.ppf(sim_sample_cdf[stock], df=parameters[i][0], loc=parameters[i][1], scale=parameters[i][2])\n",
    "\n",
    "assets_prices.drop('Date', axis=1, inplace=True)\n",
    "sim_prices = np.dot(sim_returns * assets_prices.tail(1).values.reshape(assets_prices.shape[1],), holdings)\n",
    "\n",
    "var_T = VaR(sim_prices)\n",
    "es_T = ES(sim_prices)\n",
    "\n",
    "print(\"VaR： {}\".format(var_T))\n",
    "print(\"ES： {}\".format(es_T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/lm0km0mn4zlf79tvv2679h740000gn/T/ipykernel_26178/1130395836.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars_[i]] = p2[:, i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR： 59311.71437211522\n",
      "ES： 77699.57729189718\n"
     ]
    }
   ],
   "source": [
    "asset = 'All'\n",
    "current_price, assets_prices, holdings = get_portfolio_price(portfolio, prices, asset)\n",
    "assets_returns = return_calculate(assets_prices)\n",
    "assets_returns.drop('Date', axis=1, inplace=True)\n",
    "norm_assets_returns = assets_returns - assets_returns.mean()\n",
    "parameters = []\n",
    "assets_returns_cdf = pd.DataFrame()\n",
    "\n",
    "for stock in norm_assets_returns.columns.tolist():\n",
    "    params = Fitting_t_MLE(norm_assets_returns[stock])\n",
    "    parameters.append(params)\n",
    "    assets_returns_cdf[stock] = stats.t.cdf(norm_assets_returns[stock], df=params[0], loc=params[1], scale=params[2])\n",
    "spearman_corr_matrix = assets_returns_cdf.corr(method='spearman')\n",
    "sim_sample = multivariate_normal_simulation(spearman_corr_matrix, 1000, method='pca')\n",
    "sim_sample = pd.DataFrame(sim_sample, columns=assets_returns.columns)\n",
    "sim_sample_cdf = pd.DataFrame()\n",
    "for stock in sim_sample.columns.tolist():\n",
    "    sim_sample_cdf[stock] = stats.norm.cdf(sim_sample[stock], loc=0, scale=1)\n",
    "\n",
    "sim_returns = pd.DataFrame()\n",
    "for i, stock in enumerate(sim_sample.columns.tolist()):\n",
    "    sim_returns[stock] = stats.t.ppf(sim_sample_cdf[stock], df=parameters[i][0], loc=parameters[i][1], scale=parameters[i][2])\n",
    "\n",
    "assets_prices.drop('Date', axis=1, inplace=True)\n",
    "sim_prices = np.dot(sim_returns * assets_prices.tail(1).values.reshape(assets_prices.shape[1],), holdings)\n",
    "\n",
    "var_T = VaR(sim_prices)\n",
    "es_T = ES(sim_prices)\n",
    "\n",
    "print(\"VaR： {}\".format(var_T))\n",
    "print(\"ES： {}\".format(es_T))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
